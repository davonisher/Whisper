{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-fpbkti8w\n",
      "  Resolved https://github.com/openai/whisper.git to commit c09a7ae299c4c34c5839a76380ae407e7d785914\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tiktoken==0.3.1\n",
      "  Downloading tiktoken-0.3.1-cp39-cp39-win_amd64.whl (581 kB)\n",
      "     ---------------------------------------- 0.0/581.4 kB ? eta -:--:--\n",
      "     -------------- ----------------------- 225.3/581.4 kB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 581.4/581.4 kB 7.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper==20230314) (4.65.0)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper==20230314) (1.13.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper==20230314) (8.12.0)\n",
      "Requirement already satisfied: numba in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper==20230314) (0.56.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper==20230314) (1.23.5)\n",
      "Collecting ffmpeg-python==0.2.0\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: future in c:\\users\\user\\anaconda3\\lib\\site-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.7.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from numba->openai-whisper==20230314) (65.6.3)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20230314) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper==20230314) (0.4.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=807334 sha256=16ec5db40e457ecf1b2ff73f3381507ec2f0ec9dd5d36cc9c15f8d2c31a2a54d\n",
      "  Stored in directory: C:\\Users\\User\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-eg3t09n4\\wheels\\fe\\03\\29\\e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: ffmpeg-python, tiktoken, openai-whisper\n",
      "Successfully installed ffmpeg-python-0.2.0 openai-whisper-20230314 tiktoken-0.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-req-build-fpbkti8w'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-3.27.0-py3-none-any.whl (17.3 MB)\n",
      "     ---------------------------------------- 0.0/17.3 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/17.3 MB 9.6 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 1.0/17.3 MB 12.7 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 2.2/17.3 MB 17.2 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 3.4/17.3 MB 19.7 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 4.6/17.3 MB 20.8 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 5.8/17.3 MB 21.8 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 7.0/17.3 MB 22.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 8.7/17.3 MB 24.2 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 10.2/17.3 MB 25.2 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 11.5/17.3 MB 28.5 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 13.0/17.3 MB 29.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 14.7/17.3 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 16.3/17.3 MB 32.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  17.3/17.3 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 17.3/17.3 MB 28.4 MB/s eta 0:00:00\n",
      "Collecting aiofiles\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio) (2.28.1)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "     ---------------------------------------- 0.0/84.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 84.5/84.5 kB ? eta 0:00:00\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio) (3.7.1)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.5/50.5 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.13.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "     ---------------------------------------- 0.0/200.1 kB ? eta -:--:--\n",
      "     ------------------------------------- 200.1/200.1 kB 11.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio) (6.0)\n",
      "Collecting websockets>=10.0\n",
      "  Downloading websockets-11.0.1-cp39-cp39-win_amd64.whl (124 kB)\n",
      "     ---------------------------------------- 0.0/124.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 124.5/124.5 kB 7.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Collecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 0.0/45.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 45.7/45.7 kB ? eta 0:00:00\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.8.10-cp39-none-win_amd64.whl (197 kB)\n",
      "     ---------------------------------------- 0.0/197.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 197.1/197.1 kB ? eta 0:00:00\n",
      "Collecting altair>=4.2.0\n",
      "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "     ---------------------------------------- 0.0/813.6 kB ? eta -:--:--\n",
      "     ------------------------------------- 813.6/813.6 kB 25.1 MB/s eta 0:00:00\n",
      "Collecting gradio-client>=0.1.3\n",
      "  Downloading gradio_client-0.1.3-py3-none-any.whl (286 kB)\n",
      "     ---------------------------------------- 0.0/286.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 286.2/286.2 kB ? eta 0:00:00\n",
      "Collecting semantic-version\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 0.0/57.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.0/57.0 kB ? eta 0:00:00\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: markupsafe in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.8/57.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio) (3.8.4)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
      "     ---------------------------------------- 0.0/75.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 75.3/75.3 kB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio) (4.4.0)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ------------------------- -------------- 1.4/2.2 MB 29.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.2 MB 27.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.2/2.2 MB 23.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: entrypoints in c:\\users\\user\\anaconda3\\lib\\site-packages (from altair>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: toolz in c:\\users\\user\\anaconda3\\lib\\site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio-client>=0.1.3->gradio) (23.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from gradio-client>=0.1.3->gradio) (2023.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.13.0->gradio) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->gradio) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Collecting starlette<0.27.0,>=0.26.1\n",
      "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "     ---------------------------------------- 0.0/66.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 66.9/66.9 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 0.0/70.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 70.6/70.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: idna in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (1.0.5)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (5.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->gradio) (1.26.15)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from uvicorn->gradio) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn->gradio) (0.4.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->gradio) (3.11.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=9c19f8448aef476b64a52de12cf8f2476379eab7d53332a9a6593929d3095f86\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\91\\e2\\96\\f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, pydantic, orjson, mdurl, h11, aiofiles, uvicorn, starlette, markdown-it-py, linkify-it-py, huggingface-hub, httpcore, mdit-py-plugins, httpx, fastapi, altair, gradio-client, gradio\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.1\n",
      "    Uninstalling huggingface-hub-0.10.1:\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\n",
      "Successfully installed aiofiles-23.1.0 altair-4.2.2 fastapi-0.95.1 ffmpy-0.3.0 gradio-3.27.0 gradio-client-0.1.3 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 huggingface-hub-0.13.4 linkify-it-py-2.0.0 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 orjson-3.8.10 pydantic-1.10.7 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.26.1 uc-micro-py-1.0.1 uvicorn-0.21.1 websockets-11.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install gradio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available models\n",
    "I copied the following list of available models from Whisper's repo:\n",
    "\n",
    "Size\tParameters\tEnglish-only model\tMultilingual model\tRequired VRAM\tRelative speed\n",
    "tiny\t39 M\ttiny.en\ttiny\t~1 GB\t~32x\n",
    "base\t74 M\tbase.en\tbase\t~1 GB\t~16x\n",
    "small\t244 M\tsmall.en\tsmall\t~2 GB\t~6x\n",
    "medium\t769 M\tmedium.en\tmedium\t~5 GB\t~2x\n",
    "large\t1550 M\tN/A\tlarge\t~10 GB\t1x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "\n",
    "model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(file):\n",
    "    options = dict(task=\"transcribe\", best_of=5)\n",
    "    text = model.transcribe(file, **options)[\"text\"]\n",
    "    return text.strip()\n",
    "\n",
    "def translate(file):\n",
    "    options = dict(task=\"translate\", best_of=5)\n",
    "    text = model.transcribe(file, **options)[\"text\"]\n",
    "    return text.strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio interface\n",
    "\n",
    "Here is a simple Gradio interface that you can use to record audio directly from your computer and a couple of buttons to transcribe and translate that audio.\n",
    "\n",
    "This interface was inspired by this [HuggingFace's notebook](https://colab.research.google.com/drive/1xO45FeNFBYfN6GyyUr3nEa08S0iHnWKM?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = gr.Blocks()\n",
    "\n",
    "with block:\n",
    "    with gr.Group():\n",
    "        audio = gr.Audio(\n",
    "            show_label=False,\n",
    "            source=\"microphone\",\n",
    "            type=\"filepath\"\n",
    "        )\n",
    "        with gr.Box():\n",
    "            with gr.Row().style(equal_height=True):\n",
    "                transcribe_button = gr.Button(\"Transcribe\")\n",
    "                translate_button = gr.Button(\"Translate\")\n",
    "        \n",
    "        textbox = gr.Textbox(show_label=False)\n",
    "        \n",
    "        transcribe_button.click(transcribe, inputs=[audio], outputs=[textbox])\n",
    "        translate_button.click(translate, inputs=[audio], outputs=[textbox])\n",
    " \n",
    "block.launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtranscribe(\u001b[39m\"\u001b[39;49m\u001b[39mangles.mp3\u001b[39;49m\u001b[39m\"\u001b[39;49m, fp16\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\whisper\\transcribe.py:229\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[0;32m    226\u001b[0m mel_segment \u001b[39m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mto(dtype)\n\u001b[0;32m    228\u001b[0m decode_options[\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[1;32m--> 229\u001b[0m result: DecodingResult \u001b[39m=\u001b[39m decode_with_fallback(mel_segment)\n\u001b[0;32m    230\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(result\u001b[39m.\u001b[39mtokens)\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m no_speech_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[39m# no voice activity check\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\whisper\\transcribe.py:164\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[1;34m(segment)\u001b[0m\n\u001b[0;32m    161\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m options \u001b[39m=\u001b[39m DecodingOptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, temperature\u001b[39m=\u001b[39mt)\n\u001b[1;32m--> 164\u001b[0m decode_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdecode(segment, options)\n\u001b[0;32m    166\u001b[0m needs_fallback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    168\u001b[0m     compression_ratio_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mand\u001b[39;00m decode_result\u001b[39m.\u001b[39mcompression_ratio \u001b[39m>\u001b[39m compression_ratio_threshold\n\u001b[0;32m    170\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\whisper\\decoding.py:816\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m    814\u001b[0m     options \u001b[39m=\u001b[39m replace(options, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 816\u001b[0m result \u001b[39m=\u001b[39m DecodingTask(model, options)\u001b[39m.\u001b[39;49mrun(mel)\n\u001b[0;32m    818\u001b[0m \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m single \u001b[39melse\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\whisper\\decoding.py:729\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[1;34m(self, mel)\u001b[0m\n\u001b[0;32m    726\u001b[0m tokens \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mrepeat_interleave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_group, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(audio_features\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    728\u001b[0m \u001b[39m# call the main sampling loop\u001b[39;00m\n\u001b[1;32m--> 729\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_main_loop(audio_features, tokens)\n\u001b[0;32m    731\u001b[0m \u001b[39m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[0;32m    732\u001b[0m audio_features \u001b[39m=\u001b[39m audio_features[:: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_group]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\whisper\\decoding.py:678\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[1;34m(self, audio_features, tokens)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    677\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_len):\n\u001b[1;32m--> 678\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference\u001b[39m.\u001b[39;49mlogits(tokens, audio_features)\n\u001b[0;32m    680\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    681\u001b[0m             i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mno_speech \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    682\u001b[0m         ):  \u001b[39m# save no_speech_probs\u001b[39;00m\n\u001b[0;32m    683\u001b[0m             probs_at_sot \u001b[39m=\u001b[39m logits[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msot_index]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\whisper\\decoding.py:157\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[1;34m(self, tokens, audio_features)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m tokens\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_token_length:\n\u001b[0;32m    154\u001b[0m     \u001b[39m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     tokens \u001b[39m=\u001b[39m tokens[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mdecoder(tokens, audio_features, kv_cache\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkv_cache)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\whisper\\model.py:211\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[1;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[0;32m    208\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(xa\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    210\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[1;32m--> 211\u001b[0m     x \u001b[39m=\u001b[39m block(x, xa, mask\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask, kv_cache\u001b[39m=\u001b[39;49mkv_cache)\n\u001b[0;32m    213\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln(x)\n\u001b[0;32m    214\u001b[0m logits \u001b[39m=\u001b[39m (\n\u001b[0;32m    215\u001b[0m     x \u001b[39m@\u001b[39m torch\u001b[39m.\u001b[39mtranspose(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_embedding\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdtype), \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    216\u001b[0m )\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\whisper\\model.py:139\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[1;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attn:\n\u001b[0;32m    138\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[39m=\u001b[39mkv_cache)[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 139\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp_ln(x))\n\u001b[0;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\whisper\\model.py:37\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\n\u001b[0;32m     38\u001b[0m         x,\n\u001b[0;32m     39\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mto(x\u001b[39m.\u001b[39;49mdtype),\n\u001b[0;32m     40\u001b[0m         \u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias\u001b[39m.\u001b[39;49mto(x\u001b[39m.\u001b[39;49mdtype),\n\u001b[0;32m     41\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"angles.mp3\", fp16=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "print(transcribe(r\"interview.m4a\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import docx\n",
    "\n",
    "# Get file name\n",
    "filename = \"interview.m4a\"\n",
    "name, ext = os.path.splitext(filename)\n",
    "\n",
    "# Create content string\n",
    "content = f\"The name of the file is {filename}. The file extension is {ext}.\"\n",
    "\n",
    "# Create Word document\n",
    "doc = docx.Document()\n",
    "\n",
    "# Write content string to Word document\n",
    "doc.add_paragraph(content)\n",
    "\n",
    "# Save Word document to a separate folder\n",
    "folder_name = \"Interviews transcribed\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "doc.save(f\"{folder_name}/{name}.docx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
